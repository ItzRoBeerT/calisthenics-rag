## Preguntas sobre el procesamiento del lenguaje natural natural

---

1. Â¿QuÃ© uso se hace del procesamiento del lenguaje natural?
El procesamiento del lenguaje natural se utiliza para interpretar las consultas de los usuarios, extraer y procesar informaciÃ³n contextual de documentos, y generar respuestas o rutinas personalizadas mediante un modelo de lenguaje.

En este caso, lo hemos utilizado en conjunto con un RAG para que el modelo de leguaje pueda responder a las preguntas del usuario, en caso de que el usuario pregunte sobre un tema que no se especifÃ­ca en el documento, el modelo no podrÃ¡ responderle a la pregunta (respondiendo que no conoce la respuesta).

2. Â¿Por quÃ© es Ãºtil utilizarlo?
Es Ãºtil porque permite a las mÃ¡quinas comprender y procesar el lenguaje humano, facilitando respuestas personalizadas y la extracciÃ³n eficiente de informaciÃ³n relevante de grandes volÃºmenes de datos como es el caso de este proyecto.

AdemÃ¡s, otro ejemplo que tambiÃ©n utiliza este proyecto del uso del procesamiento de lenguaje natural es la capacidad de que con un prompt bien definido, puedes lograr que un modelo de lenguaje genere un diccionario para una acciÃ³n concreta (en este caso es para montar una tabla de rutina a partir de un diccionario concreto).

---
## Detalles tÃ©cnicos

Para la realizaciÃ³n de este proyecto se ha utlizado el modelo `google/gemini-flash-1.5`, lo he utilizado debido a que posee una gran capacidad de contexto, una latencia bastante baja para tener una respuesta mÃ¡s rÃ¡pida y tiene unos costes muy baratos. Puedes ver mÃ¡s detalles si haces click [aquÃ­](https://openrouter.helicone.ai/google/gemini-flash-1.5-8b)

TambiÃ©n he utilizado `PyPDFLoader` paa cargar el pdf y poder generar la documentaciÃ³n para el modelo de lenguaje.

En cuanto a la tool, he creado mi propia tool personalizada llamada `generate_routine_pdf` la cual se encarga de generar una tabla con los dÃ­as de la semana para que el modelo de lenguaje pueda generar un pdf con la rutina. Hay que destacar que por ahora generarÃ¡ 3 tablas separando los dÃ­as de la semana ya que si la dejo en una Ãºnica tabla no se puede leer por el tamaÃ±o de las celdas asi que por el momento he dejado esta soluciÃ³n.

La tabla se genera a partir de un diccionario que el modelo de lenguaje generarÃ¡ si se le pasa la accion 'generar rutina' o 'crear rutina' en caso contrario realizarÃ¡ el RAG del documento para responder las preguntas del usuario, en caso de que el modelo de lenguaje no conozca la respuesta a la pregunta (segÃºn el documento) responderÃ¡ que no conoce dicha informaciÃ³n.

Una vez se ha generado el pdf, he creado una funciÃ³n para subir el mismo a un bucket en este caso de supabase, simplemente necesitas aÃ±adir tus credenciales al .env y llamar a la funciÃ³n `subir_pdf_a_supabase` con el nombre del documento (buscarÃ¡ en la carpeta files/`nombre_del_documento`).

---
## Diagrama conversacional de mermaid
```Mermaid
sequenceDiagram
    participant U as Usuario
    participant G as Interfaz Gradio
    participant C as Chatbot (main.py)
    participant L as LLM (ChatOpenAI)
    participant V as VectorStore (RAG)
    participant T as generate_routine_pdf (custom_tools)
    participant S as SupabaseUploader (functions)

    U->>G: EnvÃ­a mensaje
    G->>C: Llama a chatbot(message, history)
    alt El mensaje indica "generar/crear rutina"
        C->>U: "ğŸ¤” Analizando el contexto y preparando respuesta..."
        C->>U: "ğŸ‹ï¸ Generando rutina de entrenamiento..."
        C->>L: EnvÃ­a prompt para generar un diccionario de ejercicios
        L-->>C: Responde con diccionario (texto plano)
        C->>C: Parsea el diccionario (ast.literal_eval)
        C->>T: Invoca generate_routine_pdf con el diccionario
        T-->>C: Retorna figura con la tabla de rutina
        C->>C: Guarda la figura como PDF en la carpeta ./files/
        C->>S: Llama a subir_pdf_a_supabase(pdf_name)
        S-->>C: Confirma la subida a Supabase
        C->>U: "Rutina generada y subida a supabase con Ã©xito ğŸ‰"
    else El mensaje es una consulta general
        C->>V: Ejecuta similarity_search(message) para obtener contexto
        V-->>C: Retorna documentos relevantes (fragmentos del manual)
        C->>L: EnvÃ­a prompt que incluye contexto y la pregunta
        L-->>C: Genera respuesta basada en el contexto
        C->>U: EnvÃ­a la respuesta generada
    end

```

